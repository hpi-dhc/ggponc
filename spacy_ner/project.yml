title: "SpanCategorizer for overlapping NER labels"
description: "The SpanCategorizer is a component in **spaCy v3.1+** for assigning labels to contiguous spans of text proposed by a customizable suggester function. Unlike spaCy's EntityRecognizer component, the SpanCategorizer can recognize nested or overlapping spans. It also doesn't rely as heavily on consistent starting and ending words, so it may be a better fit for non-NER span labelling tasks. You do have to write a function that proposes your candidate spans, however. If your spans are often short, you could propose all spans under a certain size. You could also use syntactic constituents such as noun phrases or noun chunks, or matcher rules."
spacy_version: ">=3.1.0,<4.0.0"

vars:
  config: "spancat"  # "ner"
  gpu: -1 
  spans_key: "entities"
  data_path: "../data/ggponc_spacy"
  model: "deepset/gbert-base"
  run_name: "default"

directories: ["training", "configs", "metrics"]

workflows:
  all:
    - train
#    - evaluate

commands:

  - name: train
    help: "Train the pipeline"
    script:
      - "python -m spacy train configs/${vars.config}.cfg -o training/${vars.run_name} --gpu-id ${vars.gpu} --training.logger.run_name ${vars.run_name} --paths.base ${vars.data_path} --code chunk_and_ngram_suggester.py --components.transformer_spancat.model.name ${vars.model}"
    deps:
      - "${vars.data_path}/train.spacy"
      - "${vars.data_path}/validation.spacy"
      - "configs/${vars.config}.cfg"
    outputs:
      - "training/model-best"

#  TODO fix for spancat
#  - name: evaluate
#    help: "Evaluate on the test data and save the metrics"
#    script:
#      - "python scripts/evaluate.py ./training/model-best ./corpus/dev.spacy --output ./metrics/${vars.config}.json --gpu-id ${vars.gpu} --spans-key ${vars.spans_key}"
#    deps:
#      - "training/model-best"
#      - "corpus/dev.spacy"
#      - "scripts/evaluate.py"
#    outputs:
#      - "metrics/${vars.config}.json"

#  - name: clean
#    help: "Remove intermediate files"
#    script:
#      - "rm -rf training/*"
#      - "rm -rf metrics/*"
#      - "rm -rf corpus/*"
